<!DOCTYPE html>
<html lang="en-US">

<head>
  <meta http-equiv="X-Clacks-Overhead" content="GNU Terry Pratchett" />
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>lolwierd</title>
<meta name="title" content="lolwierd" />
<meta name="description" content="tested with text-davinci-003 using OpenAI&rsquo;s playground(opens in a new tab) unless otherwise specified. The model uses the default configurations, i.e., temperature=0.7 and top-p=1
Knobs Temperature: higher value -&gt; more deterministic output. lower value -&gt; more creative output (higher chances of hallucination?). essentially increasing the weights of other possible tokens! as temperature decreases. so obv for fact based questions -&gt; lower temp, for creative tasks -&gt; higher temp Top_p: controls how deterministic the model is at generating responses!" />
<meta name="keywords" content="" />


<meta property="og:title" content="" />
<meta property="og:description" content="tested with text-davinci-003 using OpenAI&rsquo;s playground(opens in a new tab) unless otherwise specified. The model uses the default configurations, i.e., temperature=0.7 and top-p=1
Knobs Temperature: higher value -&gt; more deterministic output. lower value -&gt; more creative output (higher chances of hallucination?). essentially increasing the weights of other possible tokens! as temperature decreases. so obv for fact based questions -&gt; lower temp, for creative tasks -&gt; higher temp Top_p: controls how deterministic the model is at generating responses!" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://lolwierd.pages.dev/notes/prompt-eng/" /><meta property="og:image" content="https://lolwierd.pages.dev/media/share.png"/><meta property="article:section" content="notes" />

<meta property="og:site_name" content="getting better" />



<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://lolwierd.pages.dev/media/share.png"/>

<meta name="twitter:title" content=""/>
<meta name="twitter:description" content="tested with text-davinci-003 using OpenAI&rsquo;s playground(opens in a new tab) unless otherwise specified. The model uses the default configurations, i.e., temperature=0.7 and top-p=1
Knobs Temperature: higher value -&gt; more deterministic output. lower value -&gt; more creative output (higher chances of hallucination?). essentially increasing the weights of other possible tokens! as temperature decreases. so obv for fact based questions -&gt; lower temp, for creative tasks -&gt; higher temp Top_p: controls how deterministic the model is at generating responses!"/>



<meta itemprop="name" content="">
<meta itemprop="description" content="tested with text-davinci-003 using OpenAI&rsquo;s playground(opens in a new tab) unless otherwise specified. The model uses the default configurations, i.e., temperature=0.7 and top-p=1
Knobs Temperature: higher value -&gt; more deterministic output. lower value -&gt; more creative output (higher chances of hallucination?). essentially increasing the weights of other possible tokens! as temperature decreases. so obv for fact based questions -&gt; lower temp, for creative tasks -&gt; higher temp Top_p: controls how deterministic the model is at generating responses!">

<meta itemprop="wordCount" content="460"><meta itemprop="image" content="https://lolwierd.pages.dev/media/share.png"/>
<meta itemprop="keywords" content="" />
<meta name="referrer" content="no-referrer-when-downgrade" />

  <style>
    body {
        font-family: Verdana, sans-serif;
        margin: auto;
        padding: 20px;
        max-width: 720px;
        text-align: left;
        background-color: #f9f9f9;
        word-wrap: break-word;
        overflow-wrap: break-word;
        line-height: 1.5;
        color: #444;
        scroll-behavior: smooth;
    }

    h1,
    h2,
    h3,
    h4,
    h5,
    h6,
    strong,
    b {
        color: #1f1f1f;
    }

    a {
        color: #2e3abc;
    }

    .title {
        text-decoration: none;
        border: 0;
    }

    .title span {
        font-weight: 400;
    }

    nav a {
        margin-right: 10px;
    }

    textarea {
        width: 100%;
        font-size: 16px;
    }

    input {
        font-size: 16px;
    }

    content {
        line-height: 1.6;
    }

    table {
        width: 100%;
    }

    img {
        max-width: 100%;
    }

    code {
        padding: 2px 5px;
        background-color: #f2f2f2;
    }

    pre code {
        color: #1f1f1f;
        display: block;
        padding: 20px;
        white-space: pre-wrap;
        font-size: 14px;
        overflow-x: auto;
    }

    div.highlight pre {
        background-color: initial;
        color: initial;
    }

    div.highlight code {
        background-color: unset;
        color: unset;
    }

    blockquote {
        border-left: 3px solid navy;
        color: #737373;
        padding-left: 12px;
        font-style: italic;
        margin-inline-start: 12px;
        margin-inline-end: 12px;

    }

    footer {
        padding: 25px;
        text-align: center;
    }

    .helptext {
        color: #777;
        font-size: small;
    }

    .errorlist {
        color: #eba613;
        font-size: small;
    }

     
    ul.blog-posts {
        list-style-type: none;
        padding: unset;
    }

    ul.blog-posts li {
        display: flex;
    }

    ul.blog-posts li span {
        flex: 0 0 130px;
    }

    ul.blog-posts li a:visited {
        color: #8b6fcb;
    }

    @media (prefers-color-scheme: dark) {
        body {
            background-color: #333;
            color: #ddd;
        }

        h1,
        h2,
        h3,
        h4,
        h5,
        h6,
        strong,
        b {
            color: #eee;
        }

        a {
            color: #8cc2dd;
             
        }

        code {
            background-color: #777;
        }

        pre code {
            color: #ddd;
        }

        blockquote {
            color: #ccc;
        }

        textarea,
        input {
            background-color: #252525;
            color: #ddd;
        }

        .helptext {
            color: #aaa;
        }
    }

    a {
        text-decoration: none;
    }

    .alt-link a {
        color: #4CA751;
    }

    a[title="notes"] {
         
         
        color: #E26D5A;
    }

    ul:has(input[type=checkbox]) {
        list-style-type: none;
        padding-inline-start: 8px;
    }

    li:has(input[type=checkbox]) {
        display: flex;
        flex-wrap: nowrap;
        gap: 4px;
    }
</style>
</head>

<body>
  <header><a href="/" class="title">
  <h2>lolwierd</h2>
</a>
<nav><a href="/">home</a>

<a href="/blog/">blog</a>

<a href="/resources/">resources</a>

<a href="/about/">about</a>


</nav>
</header>
  <main>

<content>
  <p><em>tested with text-davinci-003 using OpenAI&rsquo;s playground(opens in a new tab) unless otherwise specified. The model uses the default configurations, i.e., temperature=0.7 and top-p=1</em></p>
<a href="#knobs" class="header-link">
    <h3 id="knobs">
        Knobs
    </h3>
</a>
<ul>
<li>Temperature: higher value -&gt; more deterministic output. lower value -&gt; more creative output (<em>higher chances of hallucination?</em>). <strong>essentially increasing the weights of other possible tokens!</strong> as temperature decreases. so obv <em><strong>for fact based questions -&gt; lower temp, for creative tasks -&gt; higher temp</strong></em></li>
<li>Top_p: controls how deterministic the model is at generating responses! treat almost the same way as temperature.</li>
</ul>
<p><strong>The general recommendation is to alter one, not both.</strong></p>
<a href="#few-shot-prompting" class="header-link">
    <h3 id="few-shot-prompting">
        few-shot prompting
    </h3>
</a>
<p>enables in context learning. - ability of llms to learn new tasks given a few demonstrations.<br>
give context before asking question.</p>
<pre tabindex="0"><code>Q: &lt;Question&gt;?
A: &lt;Answer&gt;
Q: &lt;Question&gt;?
A: &lt;Answer&gt;
Q: &lt;Question&gt;?
A: &lt;Answer&gt;
Q: &lt;Question&gt;?
A:
</code></pre><pre tabindex="0"><code>This is awesome! // Positive
This is bad! // Negative
Wow that movie was rad! // Positive
What a horrible show! //
</code></pre><p>glean the structure not the specific formats.</p>
<p>moving ahead with stating the obvious. ðŸ™ƒ</p>
<p>parts of a prompt</p>
<ul>
<li>Instruction - a specific task or instruction you want the model to perform</li>
<li>Context - external information or additional context that can steer the model to better responses</li>
<li>Input Data - the input or question that we are interested to find a response for</li>
<li>Output Indicator - the type or format of the output.</li>
</ul>
<p>imma not write obv shit now. waste of time.</p>
<p>seperating the prompt into instruction and input helps.<br>
be precise. concise. dont be clever.</p>
<pre tabindex="0"><code>Explain the concept prompt engineering. Keep the explanation short, only a few sentences, and don&#39;t be too descriptive.
</code></pre><p>vs<br>
<strong></p>
<pre tabindex="0"><code>Use 2-3 sentences to explain the concept of prompt engineering to a high school student.
</code></pre></strong>
<p>dont tell what not to do. tell what to do instead. (basically avoid using directly negative speech??)</p>
<pre tabindex="0"><code>The following is an agent that recommends movies to a customer. DO NOT ASK FOR INTERESTS. DO NOT ASK FOR PERSONAL INFORMATION.
Customer: Please recommend a movie based on my interests.
Agent: 
</code></pre><p>vs<br>
<strong></p>
<pre tabindex="0"><code>The following is an agent that recommends movies to a customer. The agent is responsible to recommend a movie from the top global trending movies. It should refrain from asking users for their preferences and avoid asking for personal information. If the agent doesn&#39;t have a movie to recommend, it should respond &#34;Sorry, couldn&#39;t find a movie to recommend today.&#34;.
Customer: Please recommend a movie based on my interests.
Agent:
</code></pre></strong>
<p>mfing llms can do all nlp tasks. gibe prompt and boom. prompt with examples perform better in most cases.</p>
<p>gibe examples in da prompt if need answer in a specific format.</p>
<pre tabindex="0"><code>Classify the text into neutral, negative or positive. 
Text: I think the vacation is okay.
Sentiment: neutral 
Text: I think the food was okay. 
Sentiment:
</code></pre><a href="#zero-shot-prompting" class="header-link">
    <h3 id="zero-shot-prompting">
        zero-shot prompting
    </h3>
</a>

</content>
<p>
  
</p>

  </main>
  <footer></footer>

  </body>

</html>
